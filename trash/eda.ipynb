{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.2 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# stat 128 final project by Austin Wilson\n",
    "- dataset from kaggle competition: https://www.kaggle.com/techsash/waste-classification-data\n",
    "- there are two classes \n",
    "    - O stands for organic waste    \n",
    "    - R stands for recyclable waste\n",
    "- the purpose of this notebook\n",
    "    - is to load this data into memory as a numpy array of 64 floating point numbers \n",
    "    - use the data to train a neural network to classify images as R or O \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "import requests\n",
    "import urllib\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = \"/Users/austinwilson/coding/r/final-project/waste-recognition/DATASET/TRAIN\"\n",
    "path_test = \"/Users/austinwilson/coding/r/final-project/waste-recognition/DATASET/TEST\"\n",
    "path_to_model = '/Users/austinwilson/coding/r/final-project/waste-recognition/models/'\n",
    "model_name = \"test.hdf5\"# 'model_simple4.hdf5'"
   ]
  },
  {
   "source": [
    "this function is to load all the images in the train/test folders as 4d numpy array of float64 (for use with tensorflow)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_numpy_image_array(path, img_size = (128,128)):\n",
    "    image_names_o = os.listdir(path + \"/O\")\n",
    "    image_names_r = os.listdir(path + \"/R\")\n",
    "    numpy_img_array_o = []\n",
    "    numpy_img_array_r = []\n",
    "\n",
    "    # for the images in O category \n",
    "    for img_name in image_names_o:\n",
    "        # some images in grey scale\n",
    "        img = Image.open(path + \"/O/\" + img_name).convert(\"RGB\")\n",
    "        img = img.resize(img_size)\n",
    "        img_array = np.asarray(img)\n",
    "        if img.size == (128,128):\n",
    "            numpy_img_array_o.append(img_array)\n",
    "\n",
    "    # for the images in R category \n",
    "    for img_name in image_names_r:\n",
    "        # some images in grey scale\n",
    "        img = Image.open(path + \"/R/\" + img_name).convert(\"RGB\")\n",
    "        img = img.resize(img_size)\n",
    "        img_array = np.asarray(img)\n",
    "        if img.size == (128,128):\n",
    "            numpy_img_array_r.append(img_array)\n",
    "\n",
    "\n",
    "\n",
    "    return np.asarray(numpy_img_array_o, dtype=\"float64\"), np.asarray(numpy_img_array_r, dtype=\"float64\")"
   ]
  },
  {
   "source": [
    "## getting images into a numpy array for training/test and organic/recycle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "organic_images_train, recyclable_images_train = get_numpy_image_array(path_train)\n",
    "organic_images_test, recyclable_images_test = get_numpy_image_array(path_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate([organic_images_train,recyclable_images_train])\n",
    "x_test = np.concatenate([organic_images_test,recyclable_images_test])"
   ]
  },
  {
   "source": [
    "building the associated set of labels for x_train and x_test"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_organic_train = np.repeat(\"O\",len(organic_images_train))\n",
    "y_recycle_train = np.repeat(\"R\",len(recyclable_images_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_organic_test = np.repeat(\"O\",len(organic_images_test))\n",
    "y_recycle_test = np.repeat(\"R\",len(recyclable_images_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate([y_organic_train,y_recycle_train])\n",
    "y_test = np.concatenate([y_organic_test,y_recycle_test])"
   ]
  },
  {
   "source": [
    "creating label encoder for the values of O and R \n",
    "- not sure if I need two label encoders"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "le_1 = LabelEncoder()\n",
    "y_train = le_1.fit_transform(y_train)\n",
    "y_train = tf.keras.utils.to_categorical(y_train)\n",
    "\n",
    "le_2 = LabelEncoder()\n",
    "y_test = le_2.fit_transform(y_test)\n",
    "y_test = tf.keras.utils.to_categorical(y_test)\n",
    "\n"
   ]
  },
  {
   "source": [
    "normalize the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train / 255\n",
    "x_test = x_test / 255"
   ]
  },
  {
   "source": [
    "confirm size of all sets"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(22564, 128, 128, 3)\n(22564, 2)\n(2513, 128, 128, 3)\n(2513, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "source": [
    "## simple model with one hidden layer\n",
    "- this is the simplest model I will use just to ensure that the data is working"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"simple_model.hdf5\"\n",
    "model_simple = Sequential()\n",
    "model_simple.add(Dense(32,input_shape=(128,128,3),activation='relu'))\n",
    "model_simple.add(Flatten())\n",
    "model_simple.add(Dense(2,activation='softmax'))\n",
    "model_simple.compile(loss='categorical_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# early stopping and checkpoint to save model weights\n",
    "\n",
    "monitor = EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=2,verbose=2,mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=path_to_model+model_name,verbose=0,save_best_only=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1129/1129 - 72s - loss: 1.0876 - val_loss: 0.4730\n",
      "Epoch 2/20\n",
      "1129/1129 - 64s - loss: 0.4587 - val_loss: 0.5243\n",
      "Epoch 3/20\n",
      "1129/1129 - 61s - loss: 0.4436 - val_loss: 0.4733\n",
      "Epoch 00003: early stopping\n",
      "Epoch 1/20\n",
      "1129/1129 - 69s - loss: 0.4171 - val_loss: 0.4707\n",
      "Epoch 2/20\n",
      "1129/1129 - 64s - loss: 0.4012 - val_loss: 0.4383\n",
      "Epoch 3/20\n",
      "1129/1129 - 64s - loss: 0.3870 - val_loss: 0.4827\n",
      "Epoch 4/20\n",
      "1129/1129 - 64s - loss: 0.3702 - val_loss: 0.5378\n",
      "Epoch 00004: early stopping\n",
      "Epoch 1/20\n",
      "1129/1129 - 70s - loss: 0.3642 - val_loss: 0.5122\n",
      "Epoch 2/20\n",
      "1129/1129 - 64s - loss: 0.3556 - val_loss: 0.6423\n",
      "Epoch 3/20\n",
      "1129/1129 - 65s - loss: 0.3430 - val_loss: 0.4320\n",
      "Epoch 4/20\n",
      "1129/1129 - 65s - loss: 0.3160 - val_loss: 0.5817\n",
      "Epoch 5/20\n",
      "1129/1129 - 65s - loss: 0.3144 - val_loss: 0.5225\n",
      "Epoch 00005: early stopping\n",
      "Epoch 1/20\n",
      "1129/1129 - 71s - loss: 0.2923 - val_loss: 0.7594\n",
      "Epoch 2/20\n",
      "1129/1129 - 65s - loss: 0.2890 - val_loss: 0.6063\n",
      "Epoch 3/20\n",
      "1129/1129 - 66s - loss: 0.2814 - val_loss: 0.6570\n",
      "Epoch 4/20\n",
      "1129/1129 - 66s - loss: 0.2657 - val_loss: 0.6750\n",
      "Epoch 00004: early stopping\n",
      "Epoch 1/20\n",
      "1129/1129 - 72s - loss: 0.2553 - val_loss: 0.5583\n",
      "Epoch 2/20\n",
      "1129/1129 - 65s - loss: 0.2380 - val_loss: 0.8674\n",
      "Epoch 3/20\n",
      "1129/1129 - 66s - loss: 0.2401 - val_loss: 0.6068\n",
      "Epoch 00003: early stopping\n"
     ]
    }
   ],
   "source": [
    "# training!!\n",
    "for i in range(5):\n",
    "    model_simple.fit(x_train ,y_train,\n",
    "                    batch_size = 20,\n",
    "                    epochs = 20,\n",
    "                    verbose=2,\n",
    "                    callbacks=[monitor, checkpointer],\n",
    "                    validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "source": [
    "## predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test,axis = 1)\n",
    "y_pred = model_simple.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score:0.8450080407151532\n"
     ]
    }
   ],
   "source": [
    "f1_simple = metrics.f1_score(y_true,y_pred,average='weighted')\n",
    "print(\"F1 score:\" + str(f1_simple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.87      1401\n           1       0.87      0.77      0.82      1112\n\n    accuracy                           0.85      2513\n   macro avg       0.85      0.84      0.84      2513\nweighted avg       0.85      0.85      0.85      2513\n\n"
     ]
    }
   ],
   "source": [
    "report = metrics.classification_report(y_true,y_pred)\n",
    "print(report)"
   ]
  },
  {
   "source": [
    "## these models will not run on my computer (outsourcing to nerd friends with GPU)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "source": [
    "## VGG19"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_128 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "model_19_128 = Sequential()\n",
    "for layer in vgg19_128.layers:\n",
    "  model_19_128.add(layer)\n",
    "for layer in model_19_128.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "\n",
    "model_19_128.add(Flatten())\n",
    "model_19_128.add(Dense(2,activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer_vgg19_128 = ModelCheckpoint(filepath='path_to_model/vgg19_1.hdf5',verbose=0,save_best_only=True)\n",
    "monitor = EarlyStopping(monitor='val_loss',min_delta=1e-3,patience=2,verbose=2,mode='auto')\n",
    "model_19_128.compile(optimizer='adam',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for i in range(5):\n",
    "model_19_128.fit(x_train,y_train,\n",
    "            batch_size=32,\n",
    "            epochs=20,\n",
    "            verbose=2,\n",
    "            callbacks=[monitor,checkpointer_vgg19_128],\n",
    "            validation_data=(x_test,y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(y_test,axis = 1)\n",
    "y_pred = model_19_128.predict(x_test)\n",
    "y_pred = np.argmax(y_pred,axis = 1)\n",
    "f1_vgg19 = metrics.f1_score(y_true,y_pred,method=\"weighted\")"
   ]
  },
  {
   "source": [
    "## inception"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87916544/87910968 [==============================] - 20s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "inception = InceptionV3(input_shape = (128, 128, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 23s 0us/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "resnet = ResNet50(input_shape=(128, 128,3), include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import efficientnet.keras as efn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# efficientnet = efn.EfficientNetB0(input_shape = (224, 224, 3), include_top = False, weights = 'imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}